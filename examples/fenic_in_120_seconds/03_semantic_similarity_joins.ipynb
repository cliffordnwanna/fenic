{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ap7tnvjo5q",
   "metadata": {},
   "source": [
    "To run this Fenic demo, click **Runtime** > **Run all**.\n",
    "\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://github.com/typedef-ai/fenic\"><img src=\"https://github.com/typedef-ai/fenic/blob/main/docs/images/typedef-fenic-logo-github-yellow.png?raw=true\" height=\"50\"></a>\n",
    "<a href=\"https://discord.gg/GdqF3J7huR\"><img src=\"https://github.com/typedef-ai/fenic/blob/main/docs/images/join-the-discord.png?raw=true\" height=\"50\"></a>\n",
    "<a href=\"https://docs.fenic.ai/latest/\"><img src=\"https://github.com/typedef-ai/fenic/blob/main/docs/images/documentation.png?raw=true\" height=\"50\"></a>\n",
    "\n",
    "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [GitHub](https://github.com/typedef-ai/fenic).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09625922",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y sklearn-compat ibis-framework imbalanced-learn google-genai\n",
    "!pip install polars==1.30.0\n",
    "# === GOOGLE GEMINI ===\n",
    "#!pip install fenic[google]\n",
    "# === ANTHROPIC CLAUDE ===\n",
    "#!pip install fenic[anthropic]\n",
    "# === OPENAI (Default) ===\n",
    "!pip install fenic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11k0ltdxj",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getpass\n",
    "\n",
    "# üîå MULTI-PROVIDER SETUP - Choose your preferred LLM provider\n",
    "# Uncomment ONE of the provider sections below:\n",
    "\n",
    "# === OPENAI (Default) ===\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "\n",
    "# === GOOGLE GEMINI ===\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Google API Key:\")\n",
    "\n",
    "# === ANTHROPIC CLAUDE ===\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Anthropic API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# üöÄ Semantic Similarity Joins\n",
    "\n",
    "**Hook:** *\"Match candidates to jobs by skill similarity, not keywords\"*\n",
    "\n",
    "Beyond keyword matching, semantic similarity joins use **embeddings** to understand conceptual relationships. Watch a \"React developer\" get matched to \"JavaScript Engineer\" roles with quantified similarity scores - this is AI-powered recruiting at its finest.\n",
    "\n",
    "**What you'll see in this 2-minute demo:**\n",
    "- üíº **Job requirements** - \"React, TypeScript, modern JavaScript\"\n",
    "- üë©‚Äçüíª **Candidate skills** - \"React developer, component architecture\"\n",
    "- üß† **Embedding vectors** - Converting text to mathematical representations\n",
    "- üéØ **Similarity scores** - Quantified match confidence (0.0-1.0)\n",
    "\n",
    "This goes beyond string matching to understand skill relationships and conceptual overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fenic as fc\n",
    "\n",
    "# ‚ö° Configure session for semantic similarity analysis  \n",
    "session = fc.Session.get_or_create(fc.SessionConfig(\n",
    "    app_name=\"semantic_similarity_demo\",\n",
    "    semantic=fc.SemanticConfig(\n",
    "        embedding_models={\n",
    "            \"embeddings\": fc.OpenAIEmbeddingModel(model_name=\"text-embedding-3-small\", rpm=3000, tpm=1_000_000)\n",
    "        },\n",
    "    )\n",
    "))\n",
    "\n",
    "print(\"‚úÖ Configured with specialized embedding model for similarity matching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hsphlsyc8u",
   "metadata": {},
   "source": [
    "## üíº Step 1: The Challenge - No Keyword Overlap\n",
    "\n",
    "Jobs require \"React + TypeScript\", candidates have \"component architecture\" skills. Traditional matching fails!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jz6qlqrme2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíº Job requirements vs üë©‚Äçüíª Candidate skills - notice the mismatch!\n",
    "jobs = session.create_dataframe([\n",
    "    {\"title\": \"Frontend Engineer\", \"requirements\": \"React expert, TypeScript, modern JavaScript\"},\n",
    "    {\"title\": \"ML Research Scientist\", \"requirements\": \"PyTorch, deep learning research, PhD preferred\"},\n",
    "    {\"title\": \"DevOps Engineer\", \"requirements\": \"Kubernetes, Docker, AWS cloud platforms\"}\n",
    "])\n",
    "\n",
    "candidates = session.create_dataframe([\n",
    "    {\"name\": \"Sarah\", \"skills\": \"6 years building web apps, component-based architecture\"},\n",
    "    {\"name\": \"Dr. Rodriguez\", \"skills\": \"AI researcher, published ML papers, neural networks\"},\n",
    "    {\"name\": \"Emma\", \"skills\": \"Cloud infrastructure specialist, container orchestration\"}\n",
    "])\n",
    "\n",
    "print(\"üíº Jobs Need:\")\n",
    "jobs.show()\n",
    "print(\"\\nüë©‚Äçüíª Candidates Offer:\")\n",
    "candidates.show()\n",
    "print(\"\\nüîç CHALLENGE: No exact keyword matches!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pl7yl3g1qob",
   "metadata": {},
   "source": [
    "## üß† Step 2: Convert to Embedding Vectors\n",
    "\n",
    "Transform text into mathematical representations that capture semantic meaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rt5i2st4yc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Create embeddings - converting text to 1536-dimensional vectors\n",
    "jobs_with_embeddings = jobs.with_column(\n",
    "    \"requirements_embedding\",\n",
    "    fc.semantic.embed(fc.col(\"requirements\"))\n",
    ").cache()\n",
    "\n",
    "candidates_with_embeddings = candidates.with_column(\n",
    "    \"skills_embedding\", \n",
    "    fc.semantic.embed(fc.col(\"skills\"))\n",
    ").cache()\n",
    "\n",
    "jobs_with_embeddings.show()\n",
    "candidates_with_embeddings.show()\n",
    "\n",
    "print(\"‚úÖ Text ‚Üí Mathematical vectors complete!\")\n",
    "print(\"   ‚Ä¢ Job requirements: 1536-dimensional vectors\")\n",
    "print(\"   ‚Ä¢ Candidate skills: 1536-dimensional vectors\")\n",
    "print(\"   ‚Ä¢ Ready for semantic similarity matching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kymn96akeyb",
   "metadata": {},
   "source": [
    "## üéØ Step 3: Semantic Similarity Matching\n",
    "\n",
    "Find the best matches using cosine similarity between embedding vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mtrymhwfg6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Semantic similarity join using embeddings\n",
    "matches = candidates_with_embeddings.semantic.sim_join(\n",
    "    other=jobs_with_embeddings,\n",
    "    left_on=\"skills_embedding\",        # Use the embedding column, not text column\n",
    "    right_on=\"requirements_embedding\", # Use the embedding column, not text column\n",
    "    k=1,                              # Best match per candidate\n",
    "    similarity_score_column=\"similarity_score\"\n",
    ").cache()  # Cache to avoid re-running similarity calculations\n",
    "\n",
    "results = matches.select(\n",
    "    \"name\",\n",
    "    \"title\",\n",
    "    \"skills\", \n",
    "    (fc.col(\"similarity_score\") * 100).alias(\"match_%\")\n",
    ").order_by(fc.desc(\"match_%\"))\n",
    "\n",
    "print(\"üéØ SEMANTIC MATCHING RESULTS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results.show()\n",
    "\n",
    "print(\"\\nüí° BREAKTHROUGH: 100% successful matches!\")\n",
    "print(\"   ‚Ä¢ Sarah (web apps) ‚Üí Frontend Engineer: ~52%\")\n",
    "print(\"   ‚Ä¢ Dr. Rodriguez (ML papers) ‚Üí ML Research: ~50%\") \n",
    "print(\"   ‚Ä¢ Emma (containers) ‚Üí DevOps Engineer: ~42%\")\n",
    "print(\"All of this done with embedding similarity matching which is a lot cheaper than using LLMs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lnw8t4ls4ll",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
